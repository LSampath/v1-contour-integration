{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import brian2\n",
    "from brian2tools import *\n",
    "from brian2 import *\n",
    "from struct import unpack\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.cm as cmap\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import pickle as pickle\n",
    "import scipy\n",
    "import scipy.signal as signal\n",
    "import time\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "import gc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian2D(x, y, sigma):\n",
    "    return (1.0/(1*math.pi*(sigma**2)))*math.exp(-(1.0/(sigma**2))*(x**2 + y**2))\n",
    "\n",
    "def mexicanHat(x,y,sigma1,sigma2): \n",
    "    return gaussian2D(x,y,sigma1) - gaussian2D(x,y,sigma2)\n",
    "\n",
    "def receptiveFieldMatrix(func):\n",
    "    h = 5\n",
    "    g = np.zeros((h,h))\n",
    "    for xi in range(0,h):\n",
    "        for yi in range(0,h):\n",
    "            x = xi-int(h/2)\n",
    "            y = yi-int(h/2)\n",
    "            g[xi, yi] = func(x,y);\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_matrix_from_file(fileName, shape):\n",
    "    readout = np.load(fileName)\n",
    "#     print(readout.shape, fileName)\n",
    "    value_arr = np.zeros(shape)\n",
    "    if not readout.shape == (0,):\n",
    "        value_arr[np.int32(readout[:,0]), np.int32(readout[:,1])] = readout[:,2]\n",
    "    return value_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_stimuli(data):\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    q95 = np.percentile(data, 95)\n",
    "    data = np.where((data > q95), q95, data)\n",
    "    data = np.exp(data*15)\n",
    "    data = (data - data.min()) / (data.max() - data.min())\n",
    "    data *= 20\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_stimuli(file_name):\n",
    "    img = Image.open(file_name)\n",
    "    img.load()\n",
    "    img_arr = np.asarray(img, dtype=\"int32\")\n",
    "    stimuli = np.absolute(img_arr)/255\n",
    "    img.close()\n",
    "\n",
    "    stimuli_on = signal.convolve(stimuli, receptiveFieldMatrix(lambda x,y:mexicanHat(x,y,1,1.01)), mode='same')\n",
    "    stimuli_on = tune_stimuli(stimuli_on)\n",
    "    stimuli_off = signal.convolve(stimuli, receptiveFieldMatrix(lambda x,y:mexicanHat(x,y,1.01,1)), mode='same')\n",
    "    stimuli_off = tune_stimuli(stimuli_off)\n",
    "\n",
    "    c, axarr = subplots(1, 3, figsize = (10, 3))\n",
    "    axarr[0].imshow(stimuli, cmap = cmap.get_cmap('binary'))\n",
    "    axarr[0].title.set_text('stimuli')\n",
    "    axarr[1].imshow(stimuli_on, cmap = cmap.get_cmap('binary'))\n",
    "    axarr[1].title.set_text('stimuli_on')\n",
    "    axarr[2].imshow(stimuli_off, cmap = cmap.get_cmap('binary'))\n",
    "    axarr[2].title.set_text('stimuli_off')\n",
    "    \n",
    "    return stimuli_on, stimuli_off"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_connections():\n",
    "    for connName in connections:\n",
    "        conn = connections[connName]\n",
    "        weights = np.array(list(zip(conn.i, conn.j, conn.w)))\n",
    "        sparseWeights = weights[~(weights.transpose()[2] == 0)]\n",
    "        np.save(saved_path + connName, sparseWeights)\n",
    "        print(connName, end=' ')\n",
    "    print('connections saved')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "stimuli_path = './60_h_seq/'\n",
    "stimuli_files = ['pic_60_1.tif', 'pic_60_2.tif', 'pic_60_3.tif', 'pic_60_4.tif', 'pic_60_5.tif', 'pic_60_6.tif']\n",
    "iterations = len(stimuli_files)\n",
    "\n",
    "# initial_path = './initial_weights/'\n",
    "saved_path = './saved_weights/'\n",
    "\n",
    "fig_num = 1\n",
    "\n",
    "field_size = 2                     # 2/3/4/5/6\n",
    "w_s = field_size*1                # simple cell width\n",
    "l_s = field_size*2                # simple_cell_length\n",
    "\n",
    "c_length = 15\n",
    "r_length = (c_length*l_s)   # (c_length*2*w_s)\n",
    "orientations = 4\n",
    "\n",
    "h_index = 0\n",
    "v_index = 1\n",
    "d1_index = 2\n",
    "d2_index = 3\n",
    "\n",
    "n_LGN = r_length*r_length\n",
    "n_L4  = c_length*c_length*orientations\n",
    "n_L3  = n_L4\n",
    "n_L2  = n_L3\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "single_example_time = 0.35 * second\n",
    "resting_time = 0.15 * second\n",
    "\n",
    "delay = {}\n",
    "delay = (0*ms, 10*ms)              # min and max delay\n",
    "minDelay = delay[0]\n",
    "maxDelay = delay[1]\n",
    "deltaDelay = maxDelay - minDelay\n",
    "\n",
    "# neural model parameters\n",
    "v_rest_e = -65. * mV\n",
    "v_rest_i = -60. * mV\n",
    "v_reset_e = -65. * mV\n",
    "v_reset_i = -45. * mV\n",
    "v_thresh_e = -52. * mV\n",
    "v_thresh_i = -40. * mV\n",
    "refrac_e = 5. * ms\n",
    "refrac_i = 2. * ms\n",
    "tc_theta = 1e7 * ms\n",
    "theta_plus_e = 0.05 * mV\n",
    "offset = 20.0 * mV\n",
    "\n",
    "# STDP parameters\n",
    "tc_pre = 20*ms\n",
    "tc_post_1 = 20*ms\n",
    "tc_post_2 = 40*ms\n",
    "nu_pre =  0.0001\n",
    "nu_post = 0.01\n",
    "wmax = 100.0\n",
    "\n",
    "input_intensity = 1.\n",
    "start_input_intensity = input_intensity\n",
    "update_interval = 2\n",
    "\n",
    "#membrane dynamics\n",
    "scr_e = 'v = v_reset_e; theta += theta_plus_e; timer = 0*ms'\n",
    "v_reset_i_str = 'v = v_reset_i'\n",
    "\n",
    "v_thresh_e_str = '(v > (theta - offset + v_thresh_e)) and (timer > refrac_e)'\n",
    "v_thresh_i_str = 'v > v_thresh_i'\n",
    "\n",
    "neuron_eqs_e = '''\n",
    "        dv/dt = ((v_rest_e - v) + g_e*(-v) + g_i*(-100.*mV - v) ) / (100*ms)  : volt (unless refractory)\n",
    "        dg_e/dt = -g_e/(1.0*ms)                                    : 1\n",
    "        dg_i/dt = -g_i/(2.0*ms)                                    : 1\n",
    "        dtheta/dt = -theta/(1e7*ms)                                : volt\n",
    "        dtimer/dt = 0.1                                            : second\n",
    "'''\n",
    "\n",
    "neuron_eqs_i = '''\n",
    "        dv/dt = ((v_rest_i - v) +  g_e*(-v) + g_i*(-85.*mV - v)) / (10*ms)  : volt (unless refractory)\n",
    "        dg_e/dt = -g_e/(1.0*ms)                                    : 1\n",
    "        dg_i/dt = -g_i/(2.0*ms)                                    : 1\n",
    "'''\n",
    "\n",
    "# learning rules\n",
    "# without STDP\n",
    "model = 'w : 1'\n",
    "pre_e = 'g_e_post += w'\n",
    "pre_i = 'g_i_post += w'\n",
    "post = ''\n",
    "\n",
    "# with STDP\n",
    "stdp_model = '''\n",
    "    post2_temp                          : 1\n",
    "    w                                   : 1\n",
    "    dpre/dt   =   -pre/(tc_pre)         : 1 (event-driven)\n",
    "    dpost1/dt  = -post1/(tc_post_1)     : 1 (event-driven)\n",
    "    dpost2/dt  = -post2/(tc_post_2)     : 1 (event-driven)\n",
    "'''\n",
    "stdp_pre_e = 'pre = 1.; w = clip(w + nu_pre * post1, 0, wmax); g_e_post += w;'\n",
    "stdp_pre_i = 'pre = 1.; w = clip(w + nu_pre * post1, 0, wmax); g_i_post += w;'\n",
    "stdp_post  = 'post2_temp = post2; post1 = 1.; post2 = 1.; w = clip(w + nu_post * pre * post2_temp, 0, wmax)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1443"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neuron_groups = {}\n",
    "neuron_groups_list = [\n",
    "    ['L4_i_NF', 'i'], ['L4_NF', 'e'], ['L4_i_FN', 'i'], ['L4_FN', 'e'],\n",
    "    ['L4', 'e'],\n",
    "    ['L3', 'e'],\n",
    "    ['L2', 'i']\n",
    "]\n",
    "\n",
    "for n_g in neuron_groups_list:\n",
    "    name = n_g[0]\n",
    "    e_i = n_g[1]\n",
    "    if (e_i == 'e'):\n",
    "        neuron_groups[name] = NeuronGroup(n_L4, neuron_eqs_e, threshold=v_thresh_e_str, refractory=refrac_e, reset=scr_e, method='euler')\n",
    "        neuron_groups[name].v    = v_rest_e - 40.*mV \n",
    "        neuron_groups[name].theta = np.ones((n_L4)) * 20.0*mV\n",
    "    elif (e_i == 'i'):\n",
    "        neuron_groups[name] = NeuronGroup(n_L4, neuron_eqs_i, threshold=v_thresh_i_str, refractory=refrac_i, reset=v_reset_i_str, method='euler')\n",
    "        neuron_groups[name].v    = v_rest_i - 40.*mV \n",
    "\n",
    "\n",
    "input_groups = {}\n",
    "input_groups['LGN_on']   = PoissonGroup(n_LGN, 0*Hz)\n",
    "input_groups['LGN_off']  = PoissonGroup(n_LGN, 0*Hz)\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING    Cannot use Cython, a test compilation failed: Microsoft Visual C++ 14.0 is required. Get it with \"Microsoft Visual C++ Build Tools\": https://visualstudio.microsoft.com/downloads/ (DistutilsPlatformError) [brian2.codegen.runtime.cython_rt.cython_rt.failed_compile_test]\n",
      "INFO       Cannot use compiled code, falling back to the numpy code generation target. Note that this will likely be slower than using compiled code. Set the code generation to numpy manually to avoid this message:\n",
      "prefs.codegen.target = \"numpy\" [brian2.devices.device.codegen_fallback]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1990"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# weight_path = initial_path\n",
    "weight_path = saved_path\n",
    "connections = {}\n",
    "#[name, shape, weight_file, source, target, equation_type]\n",
    "\n",
    "input_neuron_conn = [\n",
    "    ['LGN_on_L4_NF', (n_LGN, n_L4), 'LGN_on_L4_NF.npy', 'LGN_on', 'L4_NF', 'e'],\n",
    "    ['LGN_off_L4_NF', (n_LGN, n_L4), 'LGN_off_L4_NF.npy', 'LGN_off', 'L4_NF', 'e'],\n",
    "    ['LGN_off_L4_i_NF', (n_LGN, n_L4), 'LGN_off_L4_i_NF.npy', 'LGN_off', 'L4_i_NF', 'e'],\n",
    "    ['LGN_on_L4_i_NF', (n_LGN, n_L4), 'LGN_on_L4_i_NF.npy', 'LGN_on', 'L4_i_NF', 'e'],\n",
    "    \n",
    "    ['LGN_off_L4_FN', (n_LGN, n_L4), 'LGN_off_L4_FN.npy', 'LGN_off', 'L4_FN', 'e'],\n",
    "    ['LGN_on_L4_FN', (n_LGN, n_L4), 'LGN_on_L4_FN.npy', 'LGN_on', 'L4_FN', 'e'],\n",
    "    ['LGN_on_L4_i_FN', (n_LGN, n_L4), 'LGN_on_L4_i_FN.npy', 'LGN_on', 'L4_i_FN', 'e'],\n",
    "    ['LGN_off_L4_i_FN', (n_LGN, n_L4), 'LGN_off_L4_i_FN.npy', 'LGN_off', 'L4_i_FN', 'e'],\n",
    "]\n",
    "\n",
    "neuron_neuron_conn = [\n",
    "    ['L4_i_L4_NF', (n_L4, n_L4), 'L4_i_L4_NF.npy', 'L4_i_NF', 'L4_NF', 'i', False],\n",
    "    ['L4_i_L4_FN', (n_L4, n_L4), 'L4_i_L4_FN.npy', 'L4_i_FN', 'L4_FN', 'i', False],\n",
    "    ['L4_NF_L4', (n_L4, n_L4), 'L4_NF_L4.npy', 'L4_NF', 'L4', 'e', False],\n",
    "    ['L4_FN_L4', (n_L4, n_L4), 'L4_FN_L4.npy', 'L4_FN', 'L4', 'e', False],\n",
    "    \n",
    "    ['L4_L3', (n_L4, n_L3), 'L4_L3.npy', 'L4', 'L3', 'e', False],\n",
    "    ['L3_L3', (n_L3, n_L3), 'L3_L3.npy', 'L3', 'L3', 'e', True],\n",
    "    ['L3_L2', (n_L3, n_L2), 'L3_L2.npy', 'L3', 'L2', 'e', True],\n",
    "    ['L2_L3', (n_L2, n_L3), 'L2_L3.npy', 'L2', 'L3', 'i', False],\n",
    "    \n",
    "    ['L3_L4', (n_L3, n_L4), 'L3_L4.npy', 'L3', 'L4', 'e', False]\n",
    "]\n",
    "\n",
    "\n",
    "for name, shape, weight_file, source, target, _ in input_neuron_conn:\n",
    "    weightMatrix = get_matrix_from_file(weight_path + weight_file, shape)\n",
    "    connections[name]= Synapses(input_groups[source], neuron_groups[target], model=model, on_pre=pre_e, on_post=post)\n",
    "    connections[name].connect(True)\n",
    "    connections[name].w = weightMatrix[connections[name].i, connections[name].j]\n",
    "    connections[name].delay = 'minDelay + rand() * deltaDelay'\n",
    "    \n",
    "    \n",
    "for name, shape, weight_file, source, target, equation, learn in neuron_neuron_conn:\n",
    "    if (learn):\n",
    "        model_eq = stdp_model\n",
    "        post_eq = stdp_post\n",
    "        if (equation == 'e'):\n",
    "            pre_eq = stdp_pre_e\n",
    "        elif (equation == 'i'):\n",
    "            pre_eq = stdp_pre_i\n",
    "    else:\n",
    "        model_eq = model\n",
    "        post_eq = post\n",
    "        if (equation == 'e'):\n",
    "            pre_eq = pre_e\n",
    "        elif (equation == 'i'):\n",
    "            pre_eq = pre_i\n",
    "    \n",
    "    weightMatrix = get_matrix_from_file(weight_path + weight_file, shape)\n",
    "    connections[name]= Synapses(neuron_groups[source], neuron_groups[target], model=model_eq, on_pre=pre_eq, on_post=post_eq)\n",
    "    connections[name].connect(True)\n",
    "    connections[name].w = weightMatrix[connections[name].i, connections[name].j]\n",
    "    \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "spike_counter = SpikeMonitor(neuron_groups['L4'])\n",
    "\n",
    "# used for ploting after training\n",
    "spike_monitors = {}\n",
    "\n",
    "spike_monitors['LGN_on']      = SpikeMonitor(input_groups['LGN_on'])\n",
    "spike_monitors['LGN_off']     = SpikeMonitor(input_groups['LGN_off'])\n",
    "\n",
    "for name,_ in neuron_groups_list:\n",
    "    spike_monitors[name]   = SpikeMonitor(neuron_groups[name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = Network()\n",
    "for obj_list in [neuron_groups, input_groups, connections, spike_monitors]:\n",
    "    for key in obj_list:\n",
    "        net.add(obj_list[key])\n",
    "net.add(spike_counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_spike_count = np.zeros(n_L4)\n",
    "\n",
    "for iteration in range(iterations):\n",
    "    net.run(resting_time)\n",
    "    \n",
    "    # load stimuli files\n",
    "    stimuli_on, stimuli_off = load_stimuli(stimuli_path + stimuli_files[iteration])\n",
    "    \n",
    "    # train\n",
    "    input_groups['LGN_on'].rates = 0 * Hz\n",
    "    input_groups['LGN_off'].rates = 0 * Hz\n",
    "\n",
    "    j = 0\n",
    "    while j < (num_epochs):\n",
    "        spike_rates_on = stimuli_on.reshape((n_LGN)) / 8. *  input_intensity\n",
    "        spike_rates_off = stimuli_off.reshape((n_LGN)) / 8. *  input_intensity\n",
    "\n",
    "        input_groups['LGN_on'].rates = spike_rates_on * Hz\n",
    "        input_groups['LGN_off'].rates = spike_rates_off * Hz\n",
    "\n",
    "        print('run example number:', j+1, 'of', num_epochs, 'in iteration', iteration+1, 'of', iterations)\n",
    "        net.run(single_example_time, report='text')   # 0.35 s\n",
    "\n",
    "        current_spike_count = np.asarray(spike_counter.count[:]) - previous_spike_count\n",
    "        previous_spike_count = np.copy(spike_counter.count[:])\n",
    "\n",
    "        if np.sum(current_spike_count) < 1:\n",
    "            if (input_intensity == 5):\n",
    "                break;\n",
    "            print(\"F - spike count\", np.sum(current_spike_count))\n",
    "            input_intensity += 1\n",
    "            input_groups['LGN_on'].rates = 0 * Hz\n",
    "            input_groups['LGN_off'].rates = 0 * Hz\n",
    "            net.run(resting_time) \n",
    "\n",
    "        else:     \n",
    "            print(\"S - spike count\", np.sum(current_spike_count))\n",
    "            input_groups['LGN_on'].rates = 0 * Hz\n",
    "            input_groups['LGN_off'].rates = 0 * Hz\n",
    "            net.run(resting_time)\n",
    "            input_intensity = start_input_intensity\n",
    "            j += 1\n",
    "\n",
    "        # garbage collect after each iteration\n",
    "        gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "SNN simulator",
   "language": "python",
   "name": "sim"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
